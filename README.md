# Vanguard A/B Test
### Improving the online customer experience

## Project Overview
Vanguard performed an A/B test on two variations of an online, customer facing process. This project aims to analyse the data generated by the experiement and conclude which online process performed the best.

## Installation and Setup
### Codes and Resources Used
- Jupyter Notebook 7.2.0
- Python 3.11.7
- Tableau 2024.1.3
### Python Packages Used
- Statistics: `scipy`
- Data Manipulation: `pandas` and `numpy`
- Data Visualization: `plotly`, `matplotlib`

To install external libraries, first navigate to the `./project/` directory and activate `venv-wk5-project`
1. <pre>cd ./project</pre>
2. <pre>source venv/bin/activate</pre>
Use `pip` to install external libraries:
1. <pre>pip install notebook</pre>
2. <pre>pip install pandas</pre>
3. <pre>pip install plotly</pre>
4. <pre>pip install matplotlib</pre>
5. <pre>pip install scipy</pre>

## Data
### Source Data
The data for this project was sourced from the Ironhack Data Analytics Bootcamp repository: [github.com/data-bootcamp-v4](https://github.com/data-bootcamp-v4/lessons/tree/main/5_6_eda_inf_stats_tableau/project/files_for_project)
There are 4 unique datasets in .txt format:
  1. `df_final_demo.txt` - this includes client information.
  2. `df_final_experiment_clients.txt` - this includes information about which client belongs to which group - "test" or "control".
  3. `df_final_web_data_pt_1.txt` - information about web activity part 1.
  4. `df_final_web_data_pt_2.txt` - information about web activity part 2.
### Data Preprocessing
#### Clients
**Step 1.** Create a notebook for combining and cleaning `df_final_demo.txt` and `df_final_experiment_clients.txt`.\
**Step 2.** Use `pd.read_csv` to create the dataframes.\
**Step 3.** Apply custom functions to trim all whitespace from column names and values, replace " " with "_" in column names and change all column names and string values to lowercase for ease of use.\
**Step 4.** Merge both dataframes on the `client_id` column.\
**Step 5.** Make some values and column names more explicit by, for example, replacing 'm' with 'male' in the `gender` column.\
**Step 6.** Create categorical data columns based on the numerical columns already present in the dataset.\
**Step 7.** Export the dataframe to `data/clean` for use in the analysis notebook.
#### Sessions
**Step 1.** Create a notebook for combining, cleaning and formatting `df_final_web_data_pt_1.txt`, `df_final_web_data_pt_2.txt` and `df_final_experiment_clients`.\
**Step 2.** Apply custom functions to trim all whitespace from column names and values, replace " " with "_" in column names and change all column names and string values to lowercase for ease of use.\
**Step 3.** Create a `groupby` of columns `['client_id', 'visit_id', 'process_step', 'variation']` with a count. This counts every unique combination of each client/session combination for each step in the process, which provides the basis for calculating step repetition rate.\
**Step 4.** Create a new dataframe called `session_outcome` containing a column called `process_completed` containing `yes` or `no` values.\
**Step 5.** Create a dataframe using pivot table showing the count of each step for each `client_id`/`visit_id` combination.\
**Step 6.** Create a new dataframe using pivot table to calculate the time spent in each step of the process for each unique `client_id`/`visit_it` combination.
**Step 2.** Export the clean data to the `data/clean` directory for use in the analysis notebook.
### Main Analysis
**Step 1.** After loading the clean data into dataframes, check the distribution of the categorical columns across both the `test` and `control` groups. This reveals whether or not the groups are comparable. This step was done using `pd.crosstab` with `normalize='index'`.\
**Step 2.** Create funnel diagrams showing the full process completion rate and the next-step completion rate.\
**Step 3.** Calculate the total time to completion.
